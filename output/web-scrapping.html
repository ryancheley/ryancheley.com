<!DOCTYPE html>
<html lang="en">
<head>
        <meta charset="utf-8" />
        <meta name="generator" content="Pelican" />
        <title>Web Scrapping - Passer Data (Part I)</title>
        <link rel="stylesheet" href="/theme/css/main.css" />
        <meta name="description" content="For the first time in many years I've joined a Fantasy Football league with some of my family. One of the reasons I have not engaged in the..." />
</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="/">My Place on the Internet</a></h1>
                <nav><ul>
                    <li><a href="/category/apple.html">Apple</a></li>
                    <li><a href="/category/automation.html">Automation</a></li>
                    <li><a href="/category/books.html">Books</a></li>
                    <li><a href="/category/coding.html">Coding</a></li>
                    <li><a href="/category/conferences.html">Conferences</a></li>
                    <li><a href="/category/conferenes.html">Conferenes</a></li>
                    <li><a href="/category/django.html">Django</a></li>
                    <li><a href="/category/github.html">GitHub</a></li>
                    <li><a href="/category/ios.html">iOS</a></li>
                    <li><a href="/category/macos.html">macOS</a></li>
                    <li><a href="/category/misc.html">misc</a></li>
                    <li><a href="/category/music.html">Music</a></li>
                    <li><a href="/category/musings.html">Musings</a></li>
                    <li><a href="/category/podcasts.html">Podcasts</a></li>
                    <li><a href="/category/productivity.html">Productivity</a></li>
                    <li><a href="/category/professional-development.html">Professional Development</a></li>
                    <li class="active"><a href="/category/python.html">Python</a></li>
                    <li><a href="/category/raspberry-pi.html">Raspberry Pi</a></li>
                    <li><a href="/category/server.html">Server</a></li>
                    <li><a href="/category/sports.html">Sports</a></li>
                    <li><a href="/category/web.html">Web</a></li>
                    <li><a href="/category/writing.html">Writing</a></li>
                </ul></nav>
        </header><!-- /#banner -->
<section id="content" class="body">
  <article>
    <header>
      <h1 class="entry-title">
        <a href="/web-scrapping.html" rel="bookmark"
           title="Permalink to Web Scrapping - Passer Data (Part I)">Web Scrapping - Passer Data (Part I)</a></h1>
    </header>

    <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2016-11-18T00:54:00+01:00">
                Published: Fri 18 November 2016
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="/author/ryan.html">ryan</a>
        </address>
<p>In <a href="/category/python.html">Python</a>.</p>
<p>tags: <a href="/tag/nfl.html">nfl</a> <a href="/tag/python.html">python</a> </p>
</footer><!-- /.post-info -->      <p>For the first time in <strong>many</strong> years I've joined a <a href="http://www.espn.com">Fantasy Football league</a> with some of my family. One of the reasons I have not engaged in the Fantasy football is that, frankly, I'm not very good. In fact, I'm pretty bad. I have a passing interest in Football, but my interests lie more with Baseball than football (especially in light of the NFLs policy on punishing players for some infractions of league rules, but not punishing them for infractions of societal norms (see Tom Brady and Ray Lewis respectively).</p>
<p>That being said, I am in a Fantasy Football league this year, and as of this writing am a respectable 5-5 and only 2 games back from making the playoffs with 3 games left.</p>
<p>This means that what I started on yesterday I really should have started on much sooner, but I didn't.</p>
<p>I had been counting on ESPN's 'projected points' to help guide me to victory ... it's working about as well as flipping a coin (see my record above).</p>
<p>I had a couple of days off from work this week and some time to tinker with Python, so I thought, what the hell, let's see what I can do.</p>
<p>Just to see what other people had done I did a quick <a href="http://www.google.com">Google Search</a> and found <a href="http://danielfrg.com/blog/2013/04/01/nba-scraping-data/">someone that had done what I was trying to do with data from the NBA in 2013</a>.</p>
<p>Using their post as a model I set to work.</p>
<p>The basic strategy I am mimicking is to:</p>
<ul>
<li>Get the Teams and put them into a dictionary</li>
<li><a href="https://www.ryancheley.com/blog/2016/11/18/web-scrapping-passer-data-part-ii">Get the 'matches' and put them into a dictionary</a></li>
<li>Get the player stats and put them into a dictionary for later analysis</li>
</ul>
<p>I start of importing some standard libraries <code>pandas</code>, <code>requests</code>, and <code>BeautifulSoup</code> (the other libraries are for later).</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">import</span> <span class="nn">csv</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span><span class="p">,</span> <span class="n">date</span>
</code></pre></div>

<p>Next, I need to set up some variables. <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/"><code>BeautifulSoup</code> is a Python library for pulling data out of HTML and XML files.</a>. It's pretty sweet. The code below is declaring a URL to scrape and then users the <code>requests</code> library to get the actual <code>HTML</code> of the page and put it into a variable called <code>r</code>.</p>
<div class="highlight"><pre><span></span><code><span class="n">url</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;http://espn.go.com/nfl/teams&#39;</span><span class="w"></span>
<span class="n">r</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">requests</span><span class="p">.</span><span class="k">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

<p><code>r</code> has a method called <code>text</code> which I'll use with <code>BeautifulSoup</code> to create the <code>soup</code>. The <code>'lxml'</code> declares the parser type to be used. The default is <code>lxml</code> and when I left it off I was presented with a warning, so I decided to explicitly state which parser I was going to be using to avoid the warning.</p>
<div class="highlight"><pre><span></span><code>soup = BeautifulSoup(r.text, &#39;lxml&#39;)
</code></pre></div>

<p>Next I use the <code>find_all</code> function from <code>BeautifulSoup</code>. The cool thing about <code>find_all</code> is that you can either pass just a tag element, i.e. <code>li</code> or <code>p</code>, but you can add an additional <code>class_</code> argument (notice the underscore at the end ... I missed it more than once and got an error because <code>class</code> is a keyword used by <code>Python</code>). Below I'm getting all of the `ul' elements of the class type 'medium-logos'.</p>
<div class="highlight"><pre><span></span><code>tables = soup.find_all(&#39;ul&#39;, class_=&#39;medium-logos&#39;)
</code></pre></div>

<p>Now I set up some <code>list</code> variables to hold the items I'll need for later use to create my <code>dictionary</code></p>
<div class="highlight"><pre><span></span><code>teams = []
prefix_1 = []
prefix_2 = []
teams_urls = []
</code></pre></div>

<p>Now, we do some <em>actual</em> programming:</p>
<p>Using a nested <code>for</code> loop to find all of the <code>li</code> elements in the variable called <code>lis</code> which is based on the variable <code>tables</code> (recall this is all of the <code>HTML</code> from the page I scrapped that has <em>only</em> the tags that match <code>&lt;ul class='medium-logos&gt;&lt;/ul&gt;</code> and all of the content between them).</p>
<p>The nested <code>for</code> loop creates 2 new variables which are used to populate the 4 lists from above. The creating of the <code>info</code> variable gets the a tag from the li tags. The <code>url</code> variable takes the <code>href</code> tag from the <code>info</code> variable. In order to add an item to a list (remember, all of the lists above are empty at this point) we have to invoke the method <code>append</code> on each of the lists with the data that we care about (as we look through).</p>
<p>The function <code>split</code> can be used on a string (which <code>url</code> is). It allows you to take a string apart based on a passed through value and convert the output into a list. This is super useful with URLs since there are many cases where we're trying to get to the path. Using <code>split('/')</code> allows the URL to be broken into it's constituent parts. The negative indexes used allows you to go from right to left instead of left to right.</p>
<p>To really break this down a bit, if we looked at just one of the URLs we'd get this:</p>
<p><code>http://www.espn.com/nfl/team/_/name/ten/tennessee-titans</code></p>
<p>The <code>split('/')</code> command will turn the URL into this:</p>
<p><code>['http:', '', 'www.espn.com', 'nfl', 'team', '_', 'name', 'ten', 'tennessee-titans']</code></p>
<p>Using the negative index allows us to get the right most 2 values that we need.</p>
<div class="highlight"><pre><span></span><code><span class="k">for</span> <span class="nv">table</span> <span class="nv">in</span> <span class="nv">tables</span>:
    <span class="nv">lis</span> <span class="o">=</span> <span class="nv">table</span>.<span class="nv">find_all</span><span class="ss">(</span><span class="s1">&#39;</span><span class="s">li</span><span class="s1">&#39;</span><span class="ss">)</span>
    <span class="k">for</span> <span class="nv">li</span> <span class="nv">in</span> <span class="nv">lis</span>:
        <span class="nv">info</span> <span class="o">=</span> <span class="nv">li</span>.<span class="nv">h5</span>.<span class="nv">a</span>
        <span class="nv">teams</span>.<span class="nv">append</span><span class="ss">(</span><span class="nv">info</span>.<span class="nv">text</span><span class="ss">)</span>
        <span class="nv">url</span> <span class="o">=</span> <span class="nv">info</span>[<span class="s1">&#39;</span><span class="s">href</span><span class="s1">&#39;</span>]
        <span class="nv">teams_urls</span>.<span class="nv">append</span><span class="ss">(</span><span class="nv">url</span><span class="ss">)</span>
        <span class="nv">prefix_1</span>.<span class="nv">append</span><span class="ss">(</span><span class="nv">url</span>.<span class="nv">split</span><span class="ss">(</span><span class="s1">&#39;</span><span class="s">/</span><span class="s1">&#39;</span><span class="ss">)</span>[<span class="o">-</span><span class="mi">2</span>]<span class="ss">)</span>
        <span class="nv">prefix_2</span>.<span class="nv">append</span><span class="ss">(</span><span class="nv">url</span>.<span class="nv">split</span><span class="ss">(</span><span class="s1">&#39;</span><span class="s">/</span><span class="s1">&#39;</span><span class="ss">)</span>[<span class="o">-</span><span class="mi">1</span>]<span class="ss">)</span>
</code></pre></div>

<p>Now we put it all together into a dictionary</p>
<div class="highlight"><pre><span></span><code>dic = {&#39;url&#39;: teams_urls, &#39;prefix_2&#39;: prefix_2, &#39;prefix_1&#39;: prefix_1, &#39;team&#39;: teams}
teams = pd.DataFrame(dic)
</code></pre></div>

<p>This is the end of part 1. Parts 2 and 3 will be coming later this week.</p>
<p>I've also posted all of the code to my <a href="https://github.com/miloardot">GitHub Repo</a>.</p>
    </div><!-- /.entry-content -->

  </article>
</section>
        <section id="extras" class="body">
                <div class="blogroll">
                        <h2>links</h2>
                        <ul>
                            <li><a href="https://simonwillison.net">Simon Wilison</a></li>
                            <li><a href="https://www.mattlayman.com">Matt Layman</a></li>
                            <li><a href="https://pybit.es">PyBites</a></li>
                        </ul>
                </div><!-- /.blogroll -->
                <div class="social">
                        <h2>social</h2>
                        <ul>

                            <li><a href="https://twitter.com/ryancheley/">Twitter</a></li>
                            <li><a href="https://github.com/ryancheley">GitHub</a></li>
                            <li><a href="https://www.linkedin.com/in/ryan-cheley/">LinkedIn</a></li>
                        </ul>
                </div><!-- /.social -->
        </section><!-- /#extras -->

        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Proudly powered by <a href="https://getpelican.com/">Pelican</a>, which takes great advantage of <a href="https://www.python.org/">Python</a>.
                </address><!-- /#about -->

                <p>The theme is by <a href="https://www.smashingmagazine.com/2009/08/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p>
        </footer><!-- /#contentinfo -->

</body>
</html>